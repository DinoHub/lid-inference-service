{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5f8a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.10.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.13.2)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.22.3)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.3.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from datasets) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.13)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (8.0.4)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (4.0.5)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (6.21.3)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.0.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.7.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (8.0.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (23.0)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (25.0.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.2.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.6)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (0.10.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.3.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.10.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.22.3)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.7.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.0.5)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.56.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (65.5.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa) (3.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa) (23.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install ipywidgets\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b887530e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "0.13.1+cu116\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "import librosa\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371a07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d18ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"mozilla-foundation/common_voice_9_0\", \"en\", use_auth_token=True)\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "  \"\"\"Function to preprocess the dataset with the .map method\"\"\"\n",
    "  transcription = batch[\"sentence\"]\n",
    "  \n",
    "  if transcription.startswith('\"') and transcription.endswith('\"'):\n",
    "    # we can remove trailing quotation marks as they do not affect the transcription\n",
    "    transcription = transcription[1:-1]\n",
    "  \n",
    "  if transcription[-1] not in [\".\", \"?\", \"!\"]:\n",
    "    # append a full-stop to sentences that do not end in punctuation\n",
    "    transcription = transcription + \".\"\n",
    "  \n",
    "  batch[\"sentence\"] = transcription\n",
    "  \n",
    "  return batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8fea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(prepare_dataset, desc=\"preprocess dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c74e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing helper functions\n",
    "\n",
    "#@title Prepare data and utility functions. {display-mode: \"form\"}\n",
    "#@markdown\n",
    "#@markdown You do not need to look into this cell.\n",
    "#@markdown Just execute once and you are good to go.\n",
    "#@markdown\n",
    "#@markdown In this tutorial, we will use a speech data from [VOiCES dataset](https://iqtlabs.github.io/voices/), which is licensed under Creative Commos BY 4.0.\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# Preparation of data and helper functions.\n",
    "#-------------------------------------------------------------------------------\n",
    "import io\n",
    "import os\n",
    "import math\n",
    "import tarfile\n",
    "import multiprocessing\n",
    "\n",
    "import scipy\n",
    "import librosa\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "import requests\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "[width, height] = matplotlib.rcParams['figure.figsize']\n",
    "if width < 10:\n",
    "  matplotlib.rcParams['figure.figsize'] = [width * 2.5, height]\n",
    "\n",
    "_SAMPLE_DIR = \"_sample_data\"\n",
    "\n",
    "YESNO_DATASET_PATH = os.path.join(_SAMPLE_DIR, \"yes_no\")\n",
    "os.makedirs(YESNO_DATASET_PATH, exist_ok=True)\n",
    "os.makedirs(_SAMPLE_DIR, exist_ok=True)\n",
    "\n",
    "def _fetch_data():\n",
    "  uri = [\n",
    "    (SAMPLE_WAV_URL, SAMPLE_WAV_PATH),\n",
    "    (SAMPLE_WAV_SPEECH_URL, SAMPLE_WAV_SPEECH_PATH),\n",
    "    (SAMPLE_RIR_URL, SAMPLE_RIR_PATH),\n",
    "    (SAMPLE_NOISE_URL, SAMPLE_NOISE_PATH),\n",
    "    (SAMPLE_MP3_URL, SAMPLE_MP3_PATH),\n",
    "    (SAMPLE_GSM_URL, SAMPLE_GSM_PATH),\n",
    "    (SAMPLE_TAR_URL, SAMPLE_TAR_PATH),\n",
    "  ]\n",
    "  for url, path in uri:\n",
    "    with open(path, 'wb') as file_:\n",
    "      file_.write(requests.get(url).content)\n",
    "\n",
    "_fetch_data()\n",
    "\n",
    "def _download_yesno():\n",
    "  if os.path.exists(os.path.join(YESNO_DATASET_PATH, \"waves_yesno.tar.gz\")):\n",
    "    return\n",
    "  torchaudio.datasets.YESNO(root=YESNO_DATASET_PATH, download=True)\n",
    "\n",
    "YESNO_DOWNLOAD_PROCESS = multiprocessing.Process(target=_download_yesno)\n",
    "YESNO_DOWNLOAD_PROCESS.start()\n",
    "\n",
    "def _get_sample(path, resample=None):\n",
    "  effects = [\n",
    "    [\"remix\", \"1\"]\n",
    "  ]\n",
    "  if resample:\n",
    "    effects.extend([\n",
    "      [\"lowpass\", f\"{resample // 2}\"],\n",
    "      [\"rate\", f'{resample}'],\n",
    "    ])\n",
    "  return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
    "\n",
    "def get_speech_sample(*, resample=None):\n",
    "  return _get_sample(SAMPLE_WAV_SPEECH_PATH, resample=resample)\n",
    "\n",
    "def get_sample(*, resample=None):\n",
    "  return _get_sample(SAMPLE_WAV_PATH, resample=resample)\n",
    "\n",
    "def get_rir_sample(*, resample=None, processed=False):\n",
    "  rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n",
    "  if not processed:\n",
    "    return rir_raw, sample_rate\n",
    "  rir = rir_raw[:, int(sample_rate*1.01):int(sample_rate*1.3)]\n",
    "  rir = rir / torch.norm(rir, p=2)\n",
    "  rir = torch.flip(rir, [1])\n",
    "  return rir, sample_rate\n",
    "\n",
    "def get_noise_sample(*, resample=None):\n",
    "  return _get_sample(SAMPLE_NOISE_PATH, resample=resample)\n",
    "\n",
    "def print_stats(waveform, sample_rate=None, src=None):\n",
    "  if src:\n",
    "    print(\"-\" * 10)\n",
    "    print(\"Source:\", src)\n",
    "    print(\"-\" * 10)\n",
    "  if sample_rate:\n",
    "    print(\"Sample Rate:\", sample_rate)\n",
    "  print(\"Shape:\", tuple(waveform.shape))\n",
    "  print(\"Dtype:\", waveform.dtype)\n",
    "  print(f\" - Max:     {waveform.max().item():6.3f}\")\n",
    "  print(f\" - Min:     {waveform.min().item():6.3f}\")\n",
    "  print(f\" - Mean:    {waveform.mean().item():6.3f}\")\n",
    "  print(f\" - Std Dev: {waveform.std().item():6.3f}\")\n",
    "  print()\n",
    "  print(waveform)\n",
    "  print()\n",
    "\n",
    "def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None, ylim=None):\n",
    "  waveform = waveform.numpy()\n",
    "\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "  figure, axes = plt.subplots(num_channels, 1)\n",
    "  if num_channels == 1:\n",
    "    axes = [axes]\n",
    "  for c in range(num_channels):\n",
    "    axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "    axes[c].grid(True)\n",
    "    if num_channels > 1:\n",
    "      axes[c].set_ylabel(f'Channel {c+1}')\n",
    "    if xlim:\n",
    "      axes[c].set_xlim(xlim)\n",
    "    if ylim:\n",
    "      axes[c].set_ylim(ylim)\n",
    "  figure.suptitle(title)\n",
    "  plt.show(block=False)\n",
    "\n",
    "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n",
    "  waveform = waveform.numpy()\n",
    "\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "  figure, axes = plt.subplots(num_channels, 1)\n",
    "  if num_channels == 1:\n",
    "    axes = [axes]\n",
    "  for c in range(num_channels):\n",
    "    axes[c].specgram(waveform[c], Fs=sample_rate)\n",
    "    if num_channels > 1:\n",
    "      axes[c].set_ylabel(f'Channel {c+1}')\n",
    "    if xlim:\n",
    "      axes[c].set_xlim(xlim)\n",
    "  figure.suptitle(title)\n",
    "  plt.show(block=False)\n",
    "\n",
    "def play_audio(waveform, sample_rate):\n",
    "  waveform = waveform.numpy()\n",
    "\n",
    "  num_channels, num_frames = waveform.shape\n",
    "  if num_channels == 1:\n",
    "    display(Audio(waveform[0], rate=sample_rate))\n",
    "  elif num_channels == 2:\n",
    "    display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
    "  else:\n",
    "    raise ValueError(\"Waveform with more than 2 channels are not supported.\")\n",
    "\n",
    "def inspect_file(path):\n",
    "  print(\"-\" * 10)\n",
    "  print(\"Source:\", path)\n",
    "  print(\"-\" * 10)\n",
    "  print(f\" - File size: {os.path.getsize(path)} bytes\")\n",
    "  print(f\" - {torchaudio.info(path)}\")\n",
    "\n",
    "def plot_spectrogram(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n",
    "  fig, axs = plt.subplots(1, 1)\n",
    "  axs.set_title(title or 'Spectrogram (db)')\n",
    "  axs.set_ylabel(ylabel)\n",
    "  axs.set_xlabel('frame')\n",
    "  im = axs.imshow(librosa.power_to_db(spec), origin='lower', aspect=aspect)\n",
    "  if xmax:\n",
    "    axs.set_xlim((0, xmax))\n",
    "  fig.colorbar(im, ax=axs)\n",
    "  plt.show(block=False)\n",
    "\n",
    "def plot_mel_fbank(fbank, title=None):\n",
    "  fig, axs = plt.subplots(1, 1)\n",
    "  axs.set_title(title or 'Filter bank')\n",
    "  axs.imshow(fbank, aspect='auto')\n",
    "  axs.set_ylabel('frequency bin')\n",
    "  axs.set_xlabel('mel bin')\n",
    "  plt.show(block=False)\n",
    "\n",
    "def get_spectrogram(\n",
    "    n_fft = 400,\n",
    "    win_len = None,\n",
    "    hop_len = None,\n",
    "    power = 2.0,\n",
    "):\n",
    "  waveform, _ = get_speech_sample()\n",
    "  spectrogram = T.Spectrogram(\n",
    "      n_fft=n_fft,\n",
    "      win_length=win_len,\n",
    "      hop_length=hop_len,\n",
    "      center=True,\n",
    "      pad_mode=\"reflect\",\n",
    "      power=power,\n",
    "  )\n",
    "  return spectrogram(waveform)\n",
    "\n",
    "def plot_pitch(waveform, sample_rate, pitch):\n",
    "  figure, axis = plt.subplots(1, 1)\n",
    "  axis.set_title(\"Pitch Feature\")\n",
    "  axis.grid(True)\n",
    "\n",
    "  end_time = waveform.shape[1] / sample_rate\n",
    "  time_axis = torch.linspace(0, end_time,  waveform.shape[1])\n",
    "  axis.plot(time_axis, waveform[0], linewidth=1, color='gray', alpha=0.3)\n",
    "\n",
    "  axis2 = axis.twinx()\n",
    "  time_axis = torch.linspace(0, end_time, pitch.shape[1])\n",
    "  ln2 = axis2.plot(\n",
    "      time_axis, pitch[0], linewidth=2, label='Pitch', color='green')\n",
    "\n",
    "  axis2.legend(loc=0)\n",
    "  plt.show(block=False)\n",
    "\n",
    "def plot_kaldi_pitch(waveform, sample_rate, pitch, nfcc):\n",
    "  figure, axis = plt.subplots(1, 1)\n",
    "  axis.set_title(\"Kaldi Pitch Feature\")\n",
    "  axis.grid(True)\n",
    "\n",
    "  end_time = waveform.shape[1] / sample_rate\n",
    "  time_axis = torch.linspace(0, end_time,  waveform.shape[1])\n",
    "  axis.plot(time_axis, waveform[0], linewidth=1, color='gray', alpha=0.3)\n",
    "\n",
    "  time_axis = torch.linspace(0, end_time, pitch.shape[1])\n",
    "  ln1 = axis.plot(time_axis, pitch[0], linewidth=2, label='Pitch', color='green')\n",
    "  axis.set_ylim((-1.3, 1.3))\n",
    "\n",
    "  axis2 = axis.twinx()\n",
    "  time_axis = torch.linspace(0, end_time, nfcc.shape[1])\n",
    "  ln2 = axis2.plot(\n",
    "      time_axis, nfcc[0], linewidth=2, label='NFCC', color='blue', linestyle='--')\n",
    "\n",
    "  lns = ln1 + ln2\n",
    "  labels = [l.get_label() for l in lns]\n",
    "  axis.legend(lns, labels, loc=0)\n",
    "  plt.show(block=False)\n",
    "\n",
    "DEFAULT_OFFSET = 201\n",
    "SWEEP_MAX_SAMPLE_RATE = 48000\n",
    "DEFAULT_LOWPASS_FILTER_WIDTH = 6\n",
    "DEFAULT_ROLLOFF = 0.99\n",
    "DEFAULT_RESAMPLING_METHOD = 'sinc_interpolation'\n",
    "\n",
    "def _get_log_freq(sample_rate, max_sweep_rate, offset):\n",
    "  \"\"\"Get freqs evenly spaced out in log-scale, between [0, max_sweep_rate // 2]\n",
    "\n",
    "  offset is used to avoid negative infinity `log(offset + x)`.\n",
    "\n",
    "  \"\"\"\n",
    "  half = sample_rate // 2\n",
    "  start, stop = math.log(offset), math.log(offset + max_sweep_rate // 2)\n",
    "  return torch.exp(torch.linspace(start, stop, sample_rate, dtype=torch.double)) - offset\n",
    "\n",
    "def _get_inverse_log_freq(freq, sample_rate, offset):\n",
    "  \"\"\"Find the time where the given frequency is given by _get_log_freq\"\"\"\n",
    "  half = sample_rate // 2\n",
    "  return sample_rate * (math.log(1 + freq / offset) / math.log(1 + half / offset))\n",
    "\n",
    "def _get_freq_ticks(sample_rate, offset, f_max):\n",
    "  # Given the original sample rate used for generating the sweep,\n",
    "  # find the x-axis value where the log-scale major frequency values fall in\n",
    "  time, freq = [], []\n",
    "  for exp in range(2, 5):\n",
    "    for v in range(1, 10):\n",
    "      f = v * 10 ** exp\n",
    "      if f < sample_rate // 2:\n",
    "        t = _get_inverse_log_freq(f, sample_rate, offset) / sample_rate\n",
    "        time.append(t)\n",
    "        freq.append(f)\n",
    "  t_max = _get_inverse_log_freq(f_max, sample_rate, offset) / sample_rate\n",
    "  time.append(t_max)\n",
    "  freq.append(f_max)\n",
    "  return time, freq\n",
    "\n",
    "def plot_sweep(waveform, sample_rate, title, max_sweep_rate=SWEEP_MAX_SAMPLE_RATE, offset=DEFAULT_OFFSET):\n",
    "  x_ticks = [100, 500, 1000, 5000, 10000, 20000, max_sweep_rate // 2]\n",
    "  y_ticks = [1000, 5000, 10000, 20000, sample_rate//2]\n",
    "\n",
    "  time, freq = _get_freq_ticks(max_sweep_rate, offset, sample_rate // 2)\n",
    "  freq_x = [f if f in x_ticks and f <= max_sweep_rate // 2 else None for f in freq]\n",
    "  freq_y = [f for f in freq if f >= 1000 and f in y_ticks and f <= sample_rate // 2]\n",
    "\n",
    "  figure, axis = plt.subplots(1, 1)\n",
    "  axis.specgram(waveform[0].numpy(), Fs=sample_rate)\n",
    "  plt.xticks(time, freq_x)\n",
    "  plt.yticks(freq_y, freq_y)\n",
    "  axis.set_xlabel('Original Signal Frequency (Hz, log scale)')\n",
    "  axis.set_ylabel('Waveform Frequency (Hz)')\n",
    "  axis.xaxis.grid(True, alpha=0.67)\n",
    "  axis.yaxis.grid(True, alpha=0.67)\n",
    "  figure.suptitle(f'{title} (sample rate: {sample_rate} Hz)')\n",
    "  plt.show(block=True)\n",
    "\n",
    "def get_sine_sweep(sample_rate, offset=DEFAULT_OFFSET):\n",
    "    max_sweep_rate = sample_rate\n",
    "    freq = _get_log_freq(sample_rate, max_sweep_rate, offset)\n",
    "    delta = 2 * math.pi * freq / sample_rate\n",
    "    cummulative = torch.cumsum(delta, dim=0)\n",
    "    signal = torch.sin(cummulative).unsqueeze(dim=0)\n",
    "    return signal\n",
    "\n",
    "def benchmark_resample(\n",
    "    method,\n",
    "    waveform,\n",
    "    sample_rate,\n",
    "    resample_rate,\n",
    "    lowpass_filter_width=DEFAULT_LOWPASS_FILTER_WIDTH,\n",
    "    rolloff=DEFAULT_ROLLOFF,\n",
    "    resampling_method=DEFAULT_RESAMPLING_METHOD,\n",
    "    beta=None,\n",
    "    librosa_type=None,\n",
    "    iters=5\n",
    "):\n",
    "  if method == \"functional\":\n",
    "    begin = time.time()\n",
    "    for _ in range(iters):\n",
    "      F.resample(waveform, sample_rate, resample_rate, lowpass_filter_width=lowpass_filter_width,\n",
    "                 rolloff=rolloff, resampling_method=resampling_method)\n",
    "    elapsed = time.time() - begin\n",
    "    return elapsed / iters\n",
    "  elif method == \"transforms\":\n",
    "    resampler = T.Resample(sample_rate, resample_rate, lowpass_filter_width=lowpass_filter_width,\n",
    "                           rolloff=rolloff, resampling_method=resampling_method, dtype=waveform.dtype)\n",
    "    begin = time.time()\n",
    "    for _ in range(iters):\n",
    "      resampler(waveform)\n",
    "    elapsed = time.time() - begin\n",
    "    return elapsed / iters\n",
    "  elif method == \"librosa\":\n",
    "    waveform_np = waveform.squeeze().numpy()\n",
    "    begin = time.time()\n",
    "    for _ in range(iters):\n",
    "      librosa.resample(waveform_np, sample_rate, resample_rate, res_type=librosa_type)\n",
    "    elapsed = time.time() - begin\n",
    "    return elapsed / iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76535f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../data/*.wav\"\n",
    "\n",
    "import glob\n",
    "from predict import predict\n",
    " \n",
    "files = []\n",
    "    \n",
    "# Prints all types of txt files present in a Path\n",
    "for file in glob.iglob(root, recursive=True):\n",
    "    files.append(file)\n",
    "    \n",
    "for file in files[:1]:\n",
    "    y = torchaudio.load(file, normalize = True)\n",
    "    z = predict(y[0])\n",
    "    \n",
    "    \n",
    "# #wav to tensor\n",
    "# y = torchaudio.load(path, normalize = normalize)\n",
    "# #wav to numpy\n",
    "# y = np.array(librosa.load(path, mono = True, sr = self.sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b067cb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['br: Breton'], 'Language')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c663749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a17e0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
